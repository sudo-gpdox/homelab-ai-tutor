# Changelog

## [2025-10-03] - Night 1

### Added
- Project structure with proper folders
- Ollama installation (v0.12.3)
- Llama 3.2 3B model
- VS Code setup for remote development
- Installation documentation
- README with project status

### Performance
- Ollama on CPU: ~15-25 tokens/second
- Model size: 2GB
- Usable for daily tutoring sessions

### Next Steps
- Install Cline extension
- Configure MCP for Obsidian
- Test full workflow
- Deploy to P520 (next week)
